{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img):\n",
    "    w, h = img.size\n",
    "    BASE_WIDTH, BASE_HEIGHT = 128, 32\n",
    "\n",
    "    def adjust_dim():\n",
    "        if BASE_HEIGHT >= h * BASE_WIDTH / w:\n",
    "            return BASE_WIDTH, h * BASE_WIDTH / w\n",
    "        elif BASE_WIDTH >= w * BASE_HEIGHT / h:\n",
    "            return w * BASE_HEIGHT / h, BASE_HEIGHT\n",
    "        else:\n",
    "            return BASE_WIDTH, BASE_HEIGHT\n",
    "\n",
    "    new_dim = tuple(map(int, adjust_dim()))\n",
    "    blank_img = Image.new('L', (BASE_WIDTH, BASE_HEIGHT), 255)\n",
    "    img = img.resize(new_dim, Image.ANTIALIAS)\n",
    "    assert(img.size[0] <= blank_img.size[0] and img.size[1] <= blank_img.size[1])\n",
    "    blank_img.paste(img)\n",
    "    return blank_img\n",
    "\n",
    "def image_loader(filepath):\n",
    "    X = []\n",
    "    X_filename = []\n",
    "    for dir, parent_file, files in os.walk(filepath):\n",
    "        for filename in files:\n",
    "            path = os.path.join(dir, filename)\n",
    "            if filename[-3 : ] == 'png' and os.stat(path).st_size > 0:\n",
    "                img = resize(Image.open(path).copy())\n",
    "                X.append(np.array(img))\n",
    "                X_filename.append(filename[:-4])\n",
    "    return np.array(X), np.array(X_filename)\n",
    "\n",
    "def text_loader(filepath):\n",
    "    Y = {}\n",
    "    file = open(filepath, 'r')\n",
    "    for info in file:\n",
    "        if info[0] == '#':\n",
    "            pass\n",
    "        info = info.split(\" \")\n",
    "        filename = info[0]\n",
    "        word = info[-1]\t\n",
    "        Y[filename] = word\n",
    "    return Y\n",
    "\n",
    "\n",
    "def data_loader(image_filepath, text_filepath):\n",
    "    X, X_filename = image_loader(image_filepath)\n",
    "    Y_dict = text_loader(text_filepath)\n",
    "    split = int(0.95 * len(X))\n",
    "    \n",
    "    X_train = X[:split]\n",
    "    X_test = X[split:]\n",
    "    X_filename_train = X_filename[:split]\n",
    "    X_filename_test = X_filename[split:]\n",
    "    \n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for i in range(len(X_filename_train)):\n",
    "        Y_train.append(Y_dict[X_filename_train[i]])\n",
    "    for i in range (len(X_filename_test)):\n",
    "        Y_test.append(Y_dict[X_filename_test[i]])\n",
    "    \n",
    "    Y_train = np.array(Y_train)\n",
    "    Y_test = np.array(Y_test)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepath = '/Users/prachigoyal/Desktop/htr/handwriting-recognition/words'\n",
    "text_filepath = '/Users/prachigoyal/Desktop/htr/handwriting-recognition/words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = data_loader(image_filepath, text_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(109552, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.DataFrame(X_train[0])\n",
    "print(tmp.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupCNN(cnnIn):\n",
    "        #Input size: Nc x 128 x 32 x 1\n",
    "        cnnIn = tf.expand_dims(input=cnnIn, axis=3)\n",
    "        print(\"layer 0: \" + str(cnnIn.shape))\n",
    "        cnnIn = tf.convert_to_tensor(cnnIn)\n",
    "        \n",
    "        #First Layer: Conv (5x5) + Pool(2X2), Output size : 128 x 32 x 32\n",
    "        with tf.name_scope('Conv_Pool_1'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal([5, 5, 1, 32], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(cnnIn, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool(learelu, (1, 2, 2, 1), (1, 2, 2, 1), 'VALID')\n",
    "            print(\"layer 1: \" + str(pool.shape))\n",
    "            \n",
    "        #Second Layer: Conv (5x5) + Pool(2X2), Output size : 128 x 16 x 64\n",
    "        with tf.name_scope('Conv_Pool_2'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal([5, 5, 32, 64], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool(learelu, (1, 2, 2, 1), (1, 2, 2, 1), 'VALID')\n",
    "            print(\"layer 2: \" + str(pool.shape))\n",
    "            \n",
    "        #Third Layer: Conv (5x5) + Pool(2X2), Output size : 128 x 8 x 128 or 16\n",
    "        with tf.name_scope('Conv_Pool_2'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal([5, 5, 64, 128], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            mean, variance = tf.nn.moments(conv, axes=[0])\n",
    "            conv_norm = tf.nn.batch_normalization(conv, mean, variance, offset=None, scale=None, variance_epsilon=0.001)\n",
    "            learelu = tf.nn.leaky_relu(conv_norm, alpha=0.01)\n",
    "            pool = tf.nn.max_pool(learelu, (1, 1, 2, 1), (1, 1, 2, 1), 'VALID')\n",
    "            print(\"layer 3: \" + str(pool.shape))\n",
    "            \n",
    "        # Fourth Layer: Conv (3x3) - Output size: \n",
    "        with tf.name_scope('Conv_4'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal([3, 3, 128, 128], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool(learelu, (1, 1, 2, 1), (1, 1, 2, 1), 'VALID')\n",
    "            print(\"layer 4: \" + str(pool.shape))\n",
    "        \n",
    "        # Fifth Layer: Conv (3x3) + Pool(2x2) - Output size: \n",
    "        with tf.name_scope('Conv_Pool_5'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal([3, 3, 128, 256], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool(learelu, (1, 1, 2, 1), (1, 1, 2, 1), 'VALID')\n",
    "            print(\"layer 5: \" + str(pool.shape))\n",
    "        \n",
    "        return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: (10, 32, 128, 1)\n",
      "layer 1: (10, 16, 64, 32)\n",
      "layer 2: (10, 8, 32, 64)\n",
      "layer 3: (10, 8, 16, 128)\n",
      "layer 4: (10, 8, 8, 128)\n",
      "layer 5: (10, 8, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "i = X_train[:10]\n",
    "i = tf.convert_to_tensor(i, dtype = 'float32')\n",
    "o = setupCNN(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
